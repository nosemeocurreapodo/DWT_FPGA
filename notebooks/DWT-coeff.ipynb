{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mne==1.7.1\n",
    "#!pip install PyWavelets\n",
    "#!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "from pywt import wavedec\n",
    "import scipy.stats as stats\n",
    "import time\n",
    "import numpy as np\n",
    "import time\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_raw_data(raw_electrogram_file):\n",
    "   raw = mne.io.read_raw_edf(raw_electrogram_file, preload=True) \n",
    "   rf = raw.filter(0.1,30)\n",
    "   \n",
    "   #selected_channel_name = rf.info['ch_names']\n",
    "   sample_frequency = rf.info['sfreq']\n",
    "   epoch_duration = 10\n",
    "   \n",
    "   epoch_samples = int(epoch_duration*sample_frequency)\n",
    "   \n",
    "   total_epochs = 307200// epoch_samples\n",
    "   \n",
    "   #epochs_matrix = np.zeros((total_epochs, 5, epoch_samples))  # 5 channels\n",
    "   \n",
    "   # Segmenter les données en epochs de 10 secondes\n",
    "   events = mne.make_fixed_length_events(rf, duration=epoch_duration)\n",
    "   # Créer un objet Epochs\n",
    "   epochs = mne.Epochs(rf, events, tmin=0, tmax=epoch_duration, baseline=None, detrend=1)\n",
    "   \n",
    "   # Obtenir les données des epochs sous forme de tableau numpy\n",
    "   epochs_data = epochs.get_data()\n",
    "   \n",
    "   zscores = stats.zscore(epochs_data)\n",
    "   \n",
    "   return zscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features_cpu(raw_data):\n",
    "    input_buffer = [i for i in range(len(raw_data[0, 0, :]))]\n",
    "\n",
    "    # Définition de la famille d'ondelettes à utiliser\n",
    "    wavelet = 'db4'\n",
    "\n",
    "    # Initialisation des tableaux pour stocker les caractéristiques\n",
    "    cD_Energy = np.zeros((raw_data.shape[0], 4))\n",
    "    cA_Energy = np.zeros((raw_data.shape[0], 4))\n",
    "    D_Entropy = np.zeros((raw_data.shape[0], 4))\n",
    "    A_Entropy = np.zeros((raw_data.shape[0], 4))\n",
    "    D_mean = np.zeros((raw_data.shape[0], 4))\n",
    "    A_mean = np.zeros((raw_data.shape[0], 4))\n",
    "    D_std = np.zeros((raw_data.shape[0], 4))\n",
    "    A_std = np.zeros((raw_data.shape[0], 4))\n",
    "\n",
    "    for i in range(raw_data.shape[0]):\n",
    "        for j in range(4):\n",
    "            input_buffer = raw_data[i, j, :]\n",
    "\n",
    "            coeffs = pywt.wavedec(input_buffer, wavelet, mode='symmetric', level=5, axis=0)  # Calcul de la DWT avec pywt\n",
    "\n",
    "            cD_Energy[i,j] = np.mean([np.sum(np.square(coeffs[5])),np.sum(np.square(coeffs[4])),\n",
    "                                np.sum(np.square(coeffs[3])),np.sum(np.square(coeffs[2])),\n",
    "                                np.sum(np.square(coeffs[1]))])\n",
    "            cA_Energy[i,j] = np.sum(np.square(coeffs[0]))\n",
    "            D_Entropy[i,j] = np.mean([np.sum(np.square(coeffs[5]) * np.log(np.square(coeffs[5]))),\n",
    "                                np.sum(np.square(coeffs[4]) * np.log(np.square(coeffs[4]))),\n",
    "                                np.sum(np.square(coeffs[3]) * np.log(np.square(coeffs[3]))),\n",
    "                                np.sum(np.square(coeffs[2]) * np.log(np.square(coeffs[2]))),\n",
    "                                np.sum(np.square(coeffs[1]) * np.log(np.square(coeffs[1])))])\n",
    "            A_Entropy[i,j] = np.sum(np.square(coeffs[0]) * np.log(np.square(coeffs[0])))\n",
    "            D_mean[i,j] = np.mean([np.mean(coeffs[5]),np.mean(coeffs[4]),np.mean(coeffs[3]),np.mean(coeffs[2]),np.mean(coeffs[1])])\n",
    "            A_mean[i,j] = np.mean(coeffs[0])\n",
    "            D_std[i,j] = np.mean([np.std(coeffs[5]),np.std(coeffs[4]),np.std(coeffs[3]),np.std(coeffs[2]),np.std(coeffs[1])])\n",
    "            A_std[i,j] = np.std(coeffs[0])\n",
    "            \n",
    "    return cD_Energy, cA_Energy, D_Entropy, A_Entropy, D_mean, A_mean, D_std, A_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FPGA implementation part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nfrom pynq import Overlay\\nfrom pynq import allocate\\nfrom pynq import PL\\n\\n\\nclass DWC_FEC():\\n    def __init__(self):\\n        \\n        PL.reset()\\n\\n        #overlay = Overlay(\\'design_3.bit\\')\\n        overlay = Overlay(\\'design_float.bit\\')\\n        #overlay = Overlay(\\'design_half.bit\\')\\n        #overlay = Overlay(\\'design_fixed_32_5.bit\\')\\n        #overlay = Overlay(\\'design_fixed_32_16.bit\\')\\n        #overlay = Overlay(\\'design_fixed_16_8.bit\\')\\n        #overlay = Overlay(\\'design_fixed_24_16.bit\\')\\n        #overlay = Overlay(\\'design_fixed_24_12.bit\\')\\n        #overlay = Overlay(\\'design_fixed_32_12_vhdl.bit\\')\\n\\n        self.dwt_0_hls = True\\n        self.dwt_1_hls = True\\n\\n        # Display the names of the overlay IP blocks\\n        #print(\\'IP blocks :\\', list(overlay.ip_dict.keys()))\\n\\n        self.reducer_0     = overlay.reducer_0\\n        self.reducer_1     = overlay.reducer_1\\n\\n        if self.dwt_0_hls:\\n            self.dwt_db4_hls_0 = overlay.dwt_db4_hls_0\\n        if self.dwt_1_hls:\\n            self.dwt_db4_hls_1 = overlay.dwt_db4_hls_1\\n\\n        self.dma_data_in_0 = overlay.axi_dma_data_in_0\\n        self.dma_data_in_0_send = overlay.axi_dma_data_in_0.sendchannel\\n\\n        self.dma_data_in_1 = overlay.axi_dma_data_in_1\\n        self.dma_data_in_1_send = overlay.axi_dma_data_in_1.sendchannel\\n\\n        self.dma_coeff_lo_0 = overlay.axi_dma_coeff_lo_0\\n        self.dma_coeff_lo_0_recv = overlay.axi_dma_coeff_lo_0.recvchannel\\n\\n        self.dma_coeff_lo_1 = overlay.axi_dma_coeff_lo_1\\n        self.dma_coeff_lo_1_recv = overlay.axi_dma_coeff_lo_1.recvchannel\\n\\n        #Get register offset of my parameter\\n        def get_register_offset(overlay, ip, parameter):\\n            return overlay.ip_dict[ip][\\'registers\\'][parameter][\\'address_offset\\']\\n\\n        if self.dwt_0_hls:\\n            self.DWT_0_SIZE_REGISTER = get_register_offset(overlay, \\'dwt_db4_hls_0\\', \\'size\\')\\n            #print(\\'DWT_0_SIZE_REGISTER =\\', hex(self.DWT_0_SIZE_REGISTER))\\n        if self.dwt_1_hls:\\n            self.DWT_1_SIZE_REGISTER = get_register_offset(overlay, \\'dwt_db4_hls_1\\', \\'size\\')\\n            #print(\\'DWT_1_SIZE_REGISTER =\\', hex(self.DWT_1_SIZE_REGISTER))\\n        if self.dwt_0_hls:\\n            self.DEBUG_REGISTER = get_register_offset(overlay, \\'dwt_db4_hls_0\\', \\'debug\\')\\n            #print(\\'DEBUG_REGISTER =\\', hex(self.DEBUG_REGISTER))\\n\\n        self.RED_0_SIZE_REGISTER = get_register_offset(overlay, \\'reducer_0\\', \\'size\\')\\n        #print(\\'RED_SIZE_REGISTER =\\', hex(RED_0_SIZE_REGISTER))\\n\\n        self.RED_1_SIZE_REGISTER = get_register_offset(overlay, \\'reducer_1\\', \\'size\\')\\n        #print(\\'RED_SIZE_REGISTER =\\', hex(RED_1_SIZE_REGISTER))\\n\\n        self.SQUARE_SUM_0_REGISTER = get_register_offset(overlay, \\'reducer_0\\', \\'square_sum\\')\\n        #print(\\'SQUARE_SUM_0_REGISTER =\\', hex(SQUARE_SUM_0_REGISTER))\\n\\n        self.SQUARE_SUM_1_REGISTER = get_register_offset(overlay, \\'reducer_1\\', \\'square_sum\\')\\n        #print(\\'SQUARE_SUM_1_REGISTER =\\', hex(SQUARE_SUM_1_REGISTER))\\n\\n        self.MEAN_0_REGISTER = get_register_offset(overlay, \\'reducer_0\\', \\'mean\\')\\n        #print(\\'MEAN_0_REGISTER =\\', hex(MEAN_0_REGISTER))\\n\\n        self.MEAN_1_REGISTER = get_register_offset(overlay, \\'reducer_1\\', \\'mean\\')\\n        #print(\\'MEAN_1_REGISTER =\\', hex(MEAN_1_REGISTER))\\n\\n        self.STD_0_REGISTER = get_register_offset(overlay, \\'reducer_0\\', \\'std\\')\\n        #print(\\'STD_0_REGISTER =\\', hex(STD_0_REGISTER))\\n\\n        self.STD_1_REGISTER = get_register_offset(overlay, \\'reducer_0\\', \\'std\\')\\n        #print(\\'STD_1_REGISTER =\\', hex(STD_1_REGISTER))\\n\\n        self.ENTROPY_0_REGISTER = get_register_offset(overlay, \\'reducer_0\\', \\'entropy\\')\\n        #print(\\'ENTROPY_0_REGISTER =\\', hex(ENTROPY_0_REGISTER))\\n\\n        self.ENTROPY_1_REGISTER = get_register_offset(overlay, \\'reducer_1\\', \\'entropy\\')\\n        #print(\\'ENTROPY_1_REGISTER =\\', hex(ENTROPY_1_REGISTER))\\n\\n        #Start my IPs\\n\\n        self.CONTROL_REGISTER = 0x0\\n        #dwt_db4_hls.write(CONTROL_REGISTER, 0x81)\\n\\n\\n    def print_dma_data(self, dma_channel):\\n        print(\"error: \", dma_channel.error, \" idle: \", dma_channel.idle, \" running: \", dma_channel.running)\\n\\n    def process_data(self, in_buffer_0, in_buffer_1, lo_buffer_0, lo_buffer_1):\\n        size_0 = len(in_buffer_0)\\n        dsize_0 = int((size_0 + 8 - 1)/2)\\n        size_1 = len(in_buffer_1)\\n        dsize_1 = int((size_1 + 8 - 1)/2)\\n        #print(size)\\n        #print(\"debug 1 \", dwt_db4_hls.read(DEBUG_REGISTER))\\n        \\n        if self.dwt_0_hls:\\n            self.dwt_db4_hls_0.write(self.DWT_0_SIZE_REGISTER, size_0)\\n        if self.dwt_1_hls:\\n            self.dwt_db4_hls_1.write(self.DWT_1_SIZE_REGISTER, size_1)\\n        self.reducer_0.write(self.RED_0_SIZE_REGISTER, dsize_0)\\n        self.reducer_1.write(self.RED_1_SIZE_REGISTER, dsize_1)\\n        \\n        if self.dwt_0_hls:\\n            self.dwt_db4_hls_0.write(self.CONTROL_REGISTER, 0x01)\\n        if self.dwt_1_hls:\\n            self.dwt_db4_hls_1.write(self.CONTROL_REGISTER, 0x01)\\n            \\n        self.reducer_0.write(self.CONTROL_REGISTER, 0x01)\\n        self.reducer_1.write(self.CONTROL_REGISTER, 0x01)\\n        \\n        #print(\"debug 2 \", dwt_db4_hls.read(DEBUG_REGISTER))\\n        self.dma_coeff_lo_0_recv.transfer(lo_buffer_0)\\n        self.dma_coeff_lo_1_recv.transfer(lo_buffer_1)  \\n        self.dma_data_in_0_send.transfer(in_buffer_0)  \\n        self.dma_data_in_1_send.transfer(in_buffer_1)   \\n        self.dma_data_in_0_send.wait()\\n        self.dma_data_in_1_send.wait()\\n        self.dma_coeff_lo_0_recv.wait()\\n        self.dma_coeff_lo_1_recv.wait()\\n        #print(\"debug 3 \", dwt_db4_hls.read(DEBUG_REGISTER))\\n        #dwt_db4_hls.write(CONTROL_REGISTER, 0x00)\\n        square_sum_0 = struct.unpack(\\'f\\', struct.pack(\\'I\\', self.reducer_0.read(self.SQUARE_SUM_0_REGISTER)))[0]\\n        mean_0 = struct.unpack(\\'f\\', struct.pack(\\'I\\', self.reducer_0.read(self.MEAN_0_REGISTER)))[0]\\n        std_0 = struct.unpack(\\'f\\', struct.pack(\\'I\\', self.reducer_0.read(self.STD_0_REGISTER)))[0]\\n        entropy_0 = struct.unpack(\\'f\\', struct.pack(\\'I\\', self.reducer_0.read(self.ENTROPY_0_REGISTER)))[0]\\n        square_sum_1 = struct.unpack(\\'f\\', struct.pack(\\'I\\', self.reducer_1.read(self.SQUARE_SUM_1_REGISTER)))[0]\\n        mean_1 = struct.unpack(\\'f\\', struct.pack(\\'I\\', self.reducer_1.read(self.MEAN_1_REGISTER)))[0]\\n        std_1 = struct.unpack(\\'f\\', struct.pack(\\'I\\', self.reducer_1.read(self.STD_1_REGISTER)))[0]\\n        entropy_1 = struct.unpack(\\'f\\', struct.pack(\\'I\\', self.reducer_1.read(self.ENTROPY_1_REGISTER)))[0]\\n        return [square_sum_0, mean_0, std_0, entropy_0, square_sum_1, mean_1, std_1, entropy_1]\\n    \\n    def compute_features_fpga(self, raw_data):\\n        \\n        cD_Energy_pynq = np.zeros((59, 5))\\n        cA_Energy_pynq = np.zeros((59, 5))\\n        D_Entropy_pynq = np.zeros((59, 5))\\n        A_Entropy_pynq = np.zeros((59, 5))\\n        D_mean_pynq = np.zeros((59, 5))\\n        A_mean_pynq = np.zeros((59, 5))\\n        D_std_pynq = np.zeros((59, 5))\\n        A_std_pynq = np.zeros((59, 5))\\n        \\n        #create buffers\\n        data_in_size = len(raw_data[0, 0, :])\\n        data_1_size = int((data_in_size + 8 - 1) / 2)\\n        data_2_size = int((data_1_size + 8 - 1) / 2)\\n        data_3_size = int((data_2_size + 8 - 1) / 2)\\n        data_4_size = int((data_3_size + 8 - 1) / 2)\\n        data_5_size = int((data_4_size + 8 - 1) / 2)\\n        print(data_in_size)\\n        print(data_1_size)\\n        print(data_2_size)\\n        print(data_3_size)\\n        print(data_4_size)\\n        print(data_5_size)\\n\\n        input_buffer_0 = allocate(shape=(data_in_size,), dtype=np.float32)\\n        lo_1_buffer_0 = allocate(shape=(data_1_size,), dtype=np.float32)\\n        lo_2_buffer_0 = allocate(shape=(data_2_size,), dtype=np.float32)\\n        lo_3_buffer_0 = allocate(shape=(data_3_size,), dtype=np.float32)\\n        lo_4_buffer_0 = allocate(shape=(data_4_size,), dtype=np.float32)\\n        lo_5_buffer_0 = allocate(shape=(data_5_size,), dtype=np.float32)\\n\\n        input_buffer_1 = allocate(shape=(data_in_size,), dtype=np.float32)\\n        lo_1_buffer_1 = allocate(shape=(data_1_size,), dtype=np.float32)\\n        lo_2_buffer_1 = allocate(shape=(data_2_size,), dtype=np.float32)\\n        lo_3_buffer_1 = allocate(shape=(data_3_size,), dtype=np.float32)\\n        lo_4_buffer_1 = allocate(shape=(data_4_size,), dtype=np.float32)\\n        lo_5_buffer_1 = allocate(shape=(data_5_size,), dtype=np.float32)\\n\\n        for i in range(raw_data.shape[0]):\\n            for j in range(2):\\n\\n                input_buffer_0[0:len(raw_data[i, j, :])] = raw_data[i, j, :]\\n                input_buffer_1[0:len(raw_data[i, j + 2, :])] = raw_data[i, j + 2, :]\\n\\n                squared_sum_1_0, mean_1_0, std_1_0, entropy_1_0, squared_sum_1_1, mean_1_1, std_1_1, entropy_1_1 = self.process_data(input_buffer_0, input_buffer_1, lo_1_buffer_0, lo_1_buffer_1)\\n                squared_sum_2_0, mean_2_0, std_2_0, entropy_2_0, squared_sum_2_1, mean_2_1, std_2_1, entropy_2_1 = self.process_data(lo_1_buffer_0,  lo_1_buffer_1,  lo_2_buffer_0, lo_2_buffer_1)\\n                squared_sum_3_0, mean_3_0, std_3_0, entropy_3_0, squared_sum_3_1, mean_3_1, std_3_1, entropy_3_1 = self.process_data(lo_2_buffer_0,  lo_2_buffer_1,  lo_3_buffer_0, lo_3_buffer_1)\\n                squared_sum_4_0, mean_4_0, std_4_0, entropy_4_0, squared_sum_4_1, mean_4_1, std_4_1, entropy_4_1 = self.process_data(lo_3_buffer_0,  lo_3_buffer_1,  lo_4_buffer_0, lo_4_buffer_1)\\n                squared_sum_5_0, mean_5_0, std_5_0, entropy_5_0, squared_sum_5_1, mean_5_1, std_5_1, entropy_5_1 = self.process_data(lo_4_buffer_0,  lo_4_buffer_1,  lo_5_buffer_0, lo_5_buffer_1)\\n\\n                cD_Energy_pynq[i,j] = (squared_sum_1_0 + squared_sum_2_0 + squared_sum_3_0 + squared_sum_4_0 + squared_sum_5_0)/5\\n                cA_Energy_pynq[i,j] = np.sum(np.square(lo_5_buffer_0))\\n                D_Entropy_pynq[i,j] = (entropy_1_0 + entropy_2_0 + entropy_3_0 + entropy_4_0 + entropy_5_0)/5\\n                A_Entropy_pynq[i,j] = np.sum(np.square(lo_5_buffer_0) * np.log(np.square(lo_5_buffer_0)))\\n                D_mean_pynq[i,j]    = (mean_1_0 + mean_2_0 + mean_3_0 + mean_4_0 + mean_5_0)/5\\n                A_mean_pynq[i,j]    = np.mean(lo_5_buffer_0)\\n                D_std_pynq[i,j]    = (std_1_0 + std_2_0 + std_3_0 + std_4_0 + std_5_0)/5\\n                A_std_pynq[i,j]    = np.std(lo_5_buffer_0)\\n                \\n                cD_Energy_pynq[i,j+2] = (squared_sum_1_1 + squared_sum_2_1 + squared_sum_3_1 + squared_sum_4_1 + squared_sum_5_1)/5\\n                cA_Energy_pynq[i,j+2] = np.sum(np.square(lo_5_buffer_1))\\n                D_Entropy_pynq[i,j+2] = (entropy_1_1 + entropy_2_1 + entropy_3_1 + entropy_4_1 + entropy_5_1)/5\\n                A_Entropy_pynq[i,j+2] = np.sum(np.square(lo_5_buffer_1) * np.log(np.square(lo_5_buffer_1)))\\n                D_mean_pynq[i,j+2]    = (mean_1_1 + mean_2_1 + mean_3_1 + mean_4_1 + mean_5_1)/5\\n                A_mean_pynq[i,j+2]    = np.mean(lo_5_buffer_1)\\n                D_std_pynq[i,j+2]    = (std_1_1 + std_2_1 + std_3_1 + std_4_1 + std_5_1)/5\\n                A_std_pynq[i,j+2]    = np.std(lo_5_buffer_1)\\n                \\n        return cD_Energy_pynq, cA_Energy_pynq, D_Entropy_pynq, A_Entropy_pynq, D_mean_pynq, A_mean_pynq, D_std_pynq, A_std_pynq\\n        \\n'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "from pynq import Overlay\n",
    "from pynq import allocate\n",
    "from pynq import PL\n",
    "\n",
    "\n",
    "class DWC_FEC():\n",
    "    def __init__(self):\n",
    "        \n",
    "        PL.reset()\n",
    "\n",
    "        #overlay = Overlay('design_3.bit')\n",
    "        overlay = Overlay('design_float.bit')\n",
    "        #overlay = Overlay('design_half.bit')\n",
    "        #overlay = Overlay('design_fixed_32_5.bit')\n",
    "        #overlay = Overlay('design_fixed_32_16.bit')\n",
    "        #overlay = Overlay('design_fixed_16_8.bit')\n",
    "        #overlay = Overlay('design_fixed_24_16.bit')\n",
    "        #overlay = Overlay('design_fixed_24_12.bit')\n",
    "        #overlay = Overlay('design_fixed_32_12_vhdl.bit')\n",
    "\n",
    "        self.dwt_0_hls = True\n",
    "        self.dwt_1_hls = True\n",
    "\n",
    "        # Display the names of the overlay IP blocks\n",
    "        #print('IP blocks :', list(overlay.ip_dict.keys()))\n",
    "\n",
    "        self.reducer_0     = overlay.reducer_0\n",
    "        self.reducer_1     = overlay.reducer_1\n",
    "\n",
    "        if self.dwt_0_hls:\n",
    "            self.dwt_db4_hls_0 = overlay.dwt_db4_hls_0\n",
    "        if self.dwt_1_hls:\n",
    "            self.dwt_db4_hls_1 = overlay.dwt_db4_hls_1\n",
    "\n",
    "        self.dma_data_in_0 = overlay.axi_dma_data_in_0\n",
    "        self.dma_data_in_0_send = overlay.axi_dma_data_in_0.sendchannel\n",
    "\n",
    "        self.dma_data_in_1 = overlay.axi_dma_data_in_1\n",
    "        self.dma_data_in_1_send = overlay.axi_dma_data_in_1.sendchannel\n",
    "\n",
    "        self.dma_coeff_lo_0 = overlay.axi_dma_coeff_lo_0\n",
    "        self.dma_coeff_lo_0_recv = overlay.axi_dma_coeff_lo_0.recvchannel\n",
    "\n",
    "        self.dma_coeff_lo_1 = overlay.axi_dma_coeff_lo_1\n",
    "        self.dma_coeff_lo_1_recv = overlay.axi_dma_coeff_lo_1.recvchannel\n",
    "\n",
    "        #Get register offset of my parameter\n",
    "        def get_register_offset(overlay, ip, parameter):\n",
    "            return overlay.ip_dict[ip]['registers'][parameter]['address_offset']\n",
    "\n",
    "        if self.dwt_0_hls:\n",
    "            self.DWT_0_SIZE_REGISTER = get_register_offset(overlay, 'dwt_db4_hls_0', 'size')\n",
    "            #print('DWT_0_SIZE_REGISTER =', hex(self.DWT_0_SIZE_REGISTER))\n",
    "        if self.dwt_1_hls:\n",
    "            self.DWT_1_SIZE_REGISTER = get_register_offset(overlay, 'dwt_db4_hls_1', 'size')\n",
    "            #print('DWT_1_SIZE_REGISTER =', hex(self.DWT_1_SIZE_REGISTER))\n",
    "        if self.dwt_0_hls:\n",
    "            self.DEBUG_REGISTER = get_register_offset(overlay, 'dwt_db4_hls_0', 'debug')\n",
    "            #print('DEBUG_REGISTER =', hex(self.DEBUG_REGISTER))\n",
    "\n",
    "        self.RED_0_SIZE_REGISTER = get_register_offset(overlay, 'reducer_0', 'size')\n",
    "        #print('RED_SIZE_REGISTER =', hex(RED_0_SIZE_REGISTER))\n",
    "\n",
    "        self.RED_1_SIZE_REGISTER = get_register_offset(overlay, 'reducer_1', 'size')\n",
    "        #print('RED_SIZE_REGISTER =', hex(RED_1_SIZE_REGISTER))\n",
    "\n",
    "        self.SQUARE_SUM_0_REGISTER = get_register_offset(overlay, 'reducer_0', 'square_sum')\n",
    "        #print('SQUARE_SUM_0_REGISTER =', hex(SQUARE_SUM_0_REGISTER))\n",
    "\n",
    "        self.SQUARE_SUM_1_REGISTER = get_register_offset(overlay, 'reducer_1', 'square_sum')\n",
    "        #print('SQUARE_SUM_1_REGISTER =', hex(SQUARE_SUM_1_REGISTER))\n",
    "\n",
    "        self.MEAN_0_REGISTER = get_register_offset(overlay, 'reducer_0', 'mean')\n",
    "        #print('MEAN_0_REGISTER =', hex(MEAN_0_REGISTER))\n",
    "\n",
    "        self.MEAN_1_REGISTER = get_register_offset(overlay, 'reducer_1', 'mean')\n",
    "        #print('MEAN_1_REGISTER =', hex(MEAN_1_REGISTER))\n",
    "\n",
    "        self.STD_0_REGISTER = get_register_offset(overlay, 'reducer_0', 'std')\n",
    "        #print('STD_0_REGISTER =', hex(STD_0_REGISTER))\n",
    "\n",
    "        self.STD_1_REGISTER = get_register_offset(overlay, 'reducer_0', 'std')\n",
    "        #print('STD_1_REGISTER =', hex(STD_1_REGISTER))\n",
    "\n",
    "        self.ENTROPY_0_REGISTER = get_register_offset(overlay, 'reducer_0', 'entropy')\n",
    "        #print('ENTROPY_0_REGISTER =', hex(ENTROPY_0_REGISTER))\n",
    "\n",
    "        self.ENTROPY_1_REGISTER = get_register_offset(overlay, 'reducer_1', 'entropy')\n",
    "        #print('ENTROPY_1_REGISTER =', hex(ENTROPY_1_REGISTER))\n",
    "\n",
    "        #Start my IPs\n",
    "\n",
    "        self.CONTROL_REGISTER = 0x0\n",
    "        #dwt_db4_hls.write(CONTROL_REGISTER, 0x81)\n",
    "\n",
    "\n",
    "    def print_dma_data(self, dma_channel):\n",
    "        print(\"error: \", dma_channel.error, \" idle: \", dma_channel.idle, \" running: \", dma_channel.running)\n",
    "\n",
    "    def process_data(self, in_buffer_0, in_buffer_1, lo_buffer_0, lo_buffer_1):\n",
    "        size_0 = len(in_buffer_0)\n",
    "        dsize_0 = int((size_0 + 8 - 1)/2)\n",
    "        size_1 = len(in_buffer_1)\n",
    "        dsize_1 = int((size_1 + 8 - 1)/2)\n",
    "        #print(size)\n",
    "        #print(\"debug 1 \", dwt_db4_hls.read(DEBUG_REGISTER))\n",
    "        \n",
    "        if self.dwt_0_hls:\n",
    "            self.dwt_db4_hls_0.write(self.DWT_0_SIZE_REGISTER, size_0)\n",
    "        if self.dwt_1_hls:\n",
    "            self.dwt_db4_hls_1.write(self.DWT_1_SIZE_REGISTER, size_1)\n",
    "        self.reducer_0.write(self.RED_0_SIZE_REGISTER, dsize_0)\n",
    "        self.reducer_1.write(self.RED_1_SIZE_REGISTER, dsize_1)\n",
    "        \n",
    "        if self.dwt_0_hls:\n",
    "            self.dwt_db4_hls_0.write(self.CONTROL_REGISTER, 0x01)\n",
    "        if self.dwt_1_hls:\n",
    "            self.dwt_db4_hls_1.write(self.CONTROL_REGISTER, 0x01)\n",
    "            \n",
    "        self.reducer_0.write(self.CONTROL_REGISTER, 0x01)\n",
    "        self.reducer_1.write(self.CONTROL_REGISTER, 0x01)\n",
    "        \n",
    "        #print(\"debug 2 \", dwt_db4_hls.read(DEBUG_REGISTER))\n",
    "        self.dma_coeff_lo_0_recv.transfer(lo_buffer_0)\n",
    "        self.dma_coeff_lo_1_recv.transfer(lo_buffer_1)  \n",
    "        self.dma_data_in_0_send.transfer(in_buffer_0)  \n",
    "        self.dma_data_in_1_send.transfer(in_buffer_1)   \n",
    "        self.dma_data_in_0_send.wait()\n",
    "        self.dma_data_in_1_send.wait()\n",
    "        self.dma_coeff_lo_0_recv.wait()\n",
    "        self.dma_coeff_lo_1_recv.wait()\n",
    "        #print(\"debug 3 \", dwt_db4_hls.read(DEBUG_REGISTER))\n",
    "        #dwt_db4_hls.write(CONTROL_REGISTER, 0x00)\n",
    "        square_sum_0 = struct.unpack('f', struct.pack('I', self.reducer_0.read(self.SQUARE_SUM_0_REGISTER)))[0]\n",
    "        mean_0 = struct.unpack('f', struct.pack('I', self.reducer_0.read(self.MEAN_0_REGISTER)))[0]\n",
    "        std_0 = struct.unpack('f', struct.pack('I', self.reducer_0.read(self.STD_0_REGISTER)))[0]\n",
    "        entropy_0 = struct.unpack('f', struct.pack('I', self.reducer_0.read(self.ENTROPY_0_REGISTER)))[0]\n",
    "        square_sum_1 = struct.unpack('f', struct.pack('I', self.reducer_1.read(self.SQUARE_SUM_1_REGISTER)))[0]\n",
    "        mean_1 = struct.unpack('f', struct.pack('I', self.reducer_1.read(self.MEAN_1_REGISTER)))[0]\n",
    "        std_1 = struct.unpack('f', struct.pack('I', self.reducer_1.read(self.STD_1_REGISTER)))[0]\n",
    "        entropy_1 = struct.unpack('f', struct.pack('I', self.reducer_1.read(self.ENTROPY_1_REGISTER)))[0]\n",
    "        return [square_sum_0, mean_0, std_0, entropy_0, square_sum_1, mean_1, std_1, entropy_1]\n",
    "    \n",
    "    def compute_features_fpga(self, raw_data):\n",
    "        \n",
    "        cD_Energy_pynq = np.zeros((59, 5))\n",
    "        cA_Energy_pynq = np.zeros((59, 5))\n",
    "        D_Entropy_pynq = np.zeros((59, 5))\n",
    "        A_Entropy_pynq = np.zeros((59, 5))\n",
    "        D_mean_pynq = np.zeros((59, 5))\n",
    "        A_mean_pynq = np.zeros((59, 5))\n",
    "        D_std_pynq = np.zeros((59, 5))\n",
    "        A_std_pynq = np.zeros((59, 5))\n",
    "        \n",
    "        #create buffers\n",
    "        data_in_size = len(raw_data[0, 0, :])\n",
    "        data_1_size = int((data_in_size + 8 - 1) / 2)\n",
    "        data_2_size = int((data_1_size + 8 - 1) / 2)\n",
    "        data_3_size = int((data_2_size + 8 - 1) / 2)\n",
    "        data_4_size = int((data_3_size + 8 - 1) / 2)\n",
    "        data_5_size = int((data_4_size + 8 - 1) / 2)\n",
    "        print(data_in_size)\n",
    "        print(data_1_size)\n",
    "        print(data_2_size)\n",
    "        print(data_3_size)\n",
    "        print(data_4_size)\n",
    "        print(data_5_size)\n",
    "\n",
    "        input_buffer_0 = allocate(shape=(data_in_size,), dtype=np.float32)\n",
    "        lo_1_buffer_0 = allocate(shape=(data_1_size,), dtype=np.float32)\n",
    "        lo_2_buffer_0 = allocate(shape=(data_2_size,), dtype=np.float32)\n",
    "        lo_3_buffer_0 = allocate(shape=(data_3_size,), dtype=np.float32)\n",
    "        lo_4_buffer_0 = allocate(shape=(data_4_size,), dtype=np.float32)\n",
    "        lo_5_buffer_0 = allocate(shape=(data_5_size,), dtype=np.float32)\n",
    "\n",
    "        input_buffer_1 = allocate(shape=(data_in_size,), dtype=np.float32)\n",
    "        lo_1_buffer_1 = allocate(shape=(data_1_size,), dtype=np.float32)\n",
    "        lo_2_buffer_1 = allocate(shape=(data_2_size,), dtype=np.float32)\n",
    "        lo_3_buffer_1 = allocate(shape=(data_3_size,), dtype=np.float32)\n",
    "        lo_4_buffer_1 = allocate(shape=(data_4_size,), dtype=np.float32)\n",
    "        lo_5_buffer_1 = allocate(shape=(data_5_size,), dtype=np.float32)\n",
    "\n",
    "        for i in range(raw_data.shape[0]):\n",
    "            for j in range(2):\n",
    "\n",
    "                input_buffer_0[0:len(raw_data[i, j, :])] = raw_data[i, j, :]\n",
    "                input_buffer_1[0:len(raw_data[i, j + 2, :])] = raw_data[i, j + 2, :]\n",
    "\n",
    "                squared_sum_1_0, mean_1_0, std_1_0, entropy_1_0, squared_sum_1_1, mean_1_1, std_1_1, entropy_1_1 = self.process_data(input_buffer_0, input_buffer_1, lo_1_buffer_0, lo_1_buffer_1)\n",
    "                squared_sum_2_0, mean_2_0, std_2_0, entropy_2_0, squared_sum_2_1, mean_2_1, std_2_1, entropy_2_1 = self.process_data(lo_1_buffer_0,  lo_1_buffer_1,  lo_2_buffer_0, lo_2_buffer_1)\n",
    "                squared_sum_3_0, mean_3_0, std_3_0, entropy_3_0, squared_sum_3_1, mean_3_1, std_3_1, entropy_3_1 = self.process_data(lo_2_buffer_0,  lo_2_buffer_1,  lo_3_buffer_0, lo_3_buffer_1)\n",
    "                squared_sum_4_0, mean_4_0, std_4_0, entropy_4_0, squared_sum_4_1, mean_4_1, std_4_1, entropy_4_1 = self.process_data(lo_3_buffer_0,  lo_3_buffer_1,  lo_4_buffer_0, lo_4_buffer_1)\n",
    "                squared_sum_5_0, mean_5_0, std_5_0, entropy_5_0, squared_sum_5_1, mean_5_1, std_5_1, entropy_5_1 = self.process_data(lo_4_buffer_0,  lo_4_buffer_1,  lo_5_buffer_0, lo_5_buffer_1)\n",
    "\n",
    "                cD_Energy_pynq[i,j] = (squared_sum_1_0 + squared_sum_2_0 + squared_sum_3_0 + squared_sum_4_0 + squared_sum_5_0)/5\n",
    "                cA_Energy_pynq[i,j] = np.sum(np.square(lo_5_buffer_0))\n",
    "                D_Entropy_pynq[i,j] = (entropy_1_0 + entropy_2_0 + entropy_3_0 + entropy_4_0 + entropy_5_0)/5\n",
    "                A_Entropy_pynq[i,j] = np.sum(np.square(lo_5_buffer_0) * np.log(np.square(lo_5_buffer_0)))\n",
    "                D_mean_pynq[i,j]    = (mean_1_0 + mean_2_0 + mean_3_0 + mean_4_0 + mean_5_0)/5\n",
    "                A_mean_pynq[i,j]    = np.mean(lo_5_buffer_0)\n",
    "                D_std_pynq[i,j]    = (std_1_0 + std_2_0 + std_3_0 + std_4_0 + std_5_0)/5\n",
    "                A_std_pynq[i,j]    = np.std(lo_5_buffer_0)\n",
    "                \n",
    "                cD_Energy_pynq[i,j+2] = (squared_sum_1_1 + squared_sum_2_1 + squared_sum_3_1 + squared_sum_4_1 + squared_sum_5_1)/5\n",
    "                cA_Energy_pynq[i,j+2] = np.sum(np.square(lo_5_buffer_1))\n",
    "                D_Entropy_pynq[i,j+2] = (entropy_1_1 + entropy_2_1 + entropy_3_1 + entropy_4_1 + entropy_5_1)/5\n",
    "                A_Entropy_pynq[i,j+2] = np.sum(np.square(lo_5_buffer_1) * np.log(np.square(lo_5_buffer_1)))\n",
    "                D_mean_pynq[i,j+2]    = (mean_1_1 + mean_2_1 + mean_3_1 + mean_4_1 + mean_5_1)/5\n",
    "                A_mean_pynq[i,j+2]    = np.mean(lo_5_buffer_1)\n",
    "                D_std_pynq[i,j+2]    = (std_1_1 + std_2_1 + std_3_1 + std_4_1 + std_5_1)/5\n",
    "                A_std_pynq[i,j+2]    = np.std(lo_5_buffer_1)\n",
    "                \n",
    "        return cD_Energy_pynq, cA_Energy_pynq, D_Entropy_pynq, A_Entropy_pynq, D_mean_pynq, A_mean_pynq, D_std_pynq, A_std_pynq\n",
    "        \n",
    "\"\"\"        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef compute_rmse(cpu_feature, fpga_feature):\\n    rmse = 0.0\\n    for i in range(cpu_feature.shape[0]):\\n        for j in range(4):\\n            if(fpga_feature[i,j] != fpga_feature[i,j]):\\n                print(\"some nand in fpga_feature\")\\n                continue\\n    \\n            rmse += (cpu_feature[i,j] - fpga_feature[i,j])**2\\n    rmse = np.sqrt(rmse/(cpu_feature.shape[0]*4))\\n    \\n    return rmse\\n\\ndef compute_mean_percentual_error(cpu_feature, fpga_feature):\\n    mean_error = 0.0\\n    for i in range(cpu_feature.shape[0]):\\n        for j in range(4):\\n            if(fpga_feature[i,j] != fpga_feature[i,j]):\\n                print(\"some nand in fpga_feature\")\\n                continue\\n    \\n            mean_error += np.abs((cpu_feature[i,j] - fpga_feature[i,j])/cpu_feature[i,j])\\n    mean_error = mean_error/(cpu_feature.shape[0]*4)\\n    \\n    return mean_error\\n    \\ncD_Energy_rmse = compute_rmse(cD_Energy, cD_Energy_pynq)\\ncA_Energy_rmse = compute_rmse(cA_Energy, cA_Energy_pynq)\\nD_Entropy_rmse = compute_rmse(D_Entropy, D_Entropy_pynq)\\nA_Entropy_rmse = compute_rmse(A_Entropy, A_Entropy_pynq)\\nD_mean_rmse = compute_rmse(D_mean, D_mean_pynq)\\nA_mean_rmse = compute_rmse(A_mean, A_mean_pynq)\\nD_std_rmse = compute_rmse(D_std, D_std_pynq)\\nA_std_rmse = compute_rmse(A_std, A_std_pynq)\\n\\ncD_Energy_mpe = compute_mean_percentual_error(cD_Energy, cD_Energy_pynq)\\ncA_Energy_mpe = compute_mean_percentual_error(cA_Energy, cA_Energy_pynq)\\nD_Entropy_mpe = compute_mean_percentual_error(D_Entropy, D_Entropy_pynq)\\nA_Entropy_mpe = compute_mean_percentual_error(A_Entropy, A_Entropy_pynq)\\nD_mean_mpe = compute_mean_percentual_error(D_mean, D_mean_pynq)\\nA_mean_mpe = compute_mean_percentual_error(A_mean, A_mean_pynq)\\nD_std_mpe = compute_mean_percentual_error(D_std, D_std_pynq)\\nA_std_mpe = compute_mean_percentual_error(A_std, A_std_pynq)\\n\\nprint(\"cD_Energy rmse: \", cD_Energy_rmse)\\nprint(\"cA_Energy rmse: \", cA_Energy_rmse)\\nprint(\"D_Entropy rmse: \", D_Entropy_rmse)\\nprint(\"A_Entropy rmse: \", A_Entropy_rmse)\\nprint(\"D_mean rmse: \", D_mean_rmse)\\nprint(\"A_mean rmse: \", A_mean_rmse)\\nprint(\"D_std rmse: \", D_std_rmse)\\nprint(\"A_std rmse: \", A_std_rmse)\\n\\nprint(\"cD_Energy mean % error: \", cD_Energy_mpe)\\nprint(\"cA_Energy rmse: \", cA_Energy_mpe)\\nprint(\"D_Entropy mean % error: \", D_Entropy_mpe)\\nprint(\"A_Entropy rmse: \", A_Entropy_mpe)\\nprint(\"D_mean mean % error: \", D_mean_mpe)\\nprint(\"A_mean rmse: \", A_mean_mpe)\\nprint(\"D_std mean % error: \", D_std_mpe)\\nprint(\"A_std rmse: \", A_std_mpe)\\n'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def compute_rmse(cpu_feature, fpga_feature):\n",
    "    rmse = 0.0\n",
    "    for i in range(cpu_feature.shape[0]):\n",
    "        for j in range(4):\n",
    "            if(fpga_feature[i,j] != fpga_feature[i,j]):\n",
    "                print(\"some nand in fpga_feature\")\n",
    "                continue\n",
    "    \n",
    "            rmse += (cpu_feature[i,j] - fpga_feature[i,j])**2\n",
    "    rmse = np.sqrt(rmse/(cpu_feature.shape[0]*4))\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "def compute_mean_percentual_error(cpu_feature, fpga_feature):\n",
    "    mean_error = 0.0\n",
    "    for i in range(cpu_feature.shape[0]):\n",
    "        for j in range(4):\n",
    "            if(fpga_feature[i,j] != fpga_feature[i,j]):\n",
    "                print(\"some nand in fpga_feature\")\n",
    "                continue\n",
    "    \n",
    "            mean_error += np.abs((cpu_feature[i,j] - fpga_feature[i,j])/cpu_feature[i,j])\n",
    "    mean_error = mean_error/(cpu_feature.shape[0]*4)\n",
    "    \n",
    "    return mean_error\n",
    "    \n",
    "cD_Energy_rmse = compute_rmse(cD_Energy, cD_Energy_pynq)\n",
    "cA_Energy_rmse = compute_rmse(cA_Energy, cA_Energy_pynq)\n",
    "D_Entropy_rmse = compute_rmse(D_Entropy, D_Entropy_pynq)\n",
    "A_Entropy_rmse = compute_rmse(A_Entropy, A_Entropy_pynq)\n",
    "D_mean_rmse = compute_rmse(D_mean, D_mean_pynq)\n",
    "A_mean_rmse = compute_rmse(A_mean, A_mean_pynq)\n",
    "D_std_rmse = compute_rmse(D_std, D_std_pynq)\n",
    "A_std_rmse = compute_rmse(A_std, A_std_pynq)\n",
    "\n",
    "cD_Energy_mpe = compute_mean_percentual_error(cD_Energy, cD_Energy_pynq)\n",
    "cA_Energy_mpe = compute_mean_percentual_error(cA_Energy, cA_Energy_pynq)\n",
    "D_Entropy_mpe = compute_mean_percentual_error(D_Entropy, D_Entropy_pynq)\n",
    "A_Entropy_mpe = compute_mean_percentual_error(A_Entropy, A_Entropy_pynq)\n",
    "D_mean_mpe = compute_mean_percentual_error(D_mean, D_mean_pynq)\n",
    "A_mean_mpe = compute_mean_percentual_error(A_mean, A_mean_pynq)\n",
    "D_std_mpe = compute_mean_percentual_error(D_std, D_std_pynq)\n",
    "A_std_mpe = compute_mean_percentual_error(A_std, A_std_pynq)\n",
    "\n",
    "print(\"cD_Energy rmse: \", cD_Energy_rmse)\n",
    "print(\"cA_Energy rmse: \", cA_Energy_rmse)\n",
    "print(\"D_Entropy rmse: \", D_Entropy_rmse)\n",
    "print(\"A_Entropy rmse: \", A_Entropy_rmse)\n",
    "print(\"D_mean rmse: \", D_mean_rmse)\n",
    "print(\"A_mean rmse: \", A_mean_rmse)\n",
    "print(\"D_std rmse: \", D_std_rmse)\n",
    "print(\"A_std rmse: \", A_std_rmse)\n",
    "\n",
    "print(\"cD_Energy mean % error: \", cD_Energy_mpe)\n",
    "print(\"cA_Energy rmse: \", cA_Energy_mpe)\n",
    "print(\"D_Entropy mean % error: \", D_Entropy_mpe)\n",
    "print(\"A_Entropy rmse: \", A_Entropy_mpe)\n",
    "print(\"D_mean mean % error: \", D_mean_mpe)\n",
    "print(\"A_mean rmse: \", A_mean_mpe)\n",
    "print(\"D_std mean % error: \", D_std_mpe)\n",
    "print(\"A_std rmse: \", A_std_mpe)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataframe(cD_Energy, cA_Energy, D_Entropy, A_Entropy, D_mean, A_mean, D_std, A_std, state):\n",
    "    df = pd.DataFrame(cD_Energy)\n",
    "    df1 = pd.DataFrame(cA_Energy)\n",
    "    df2 = pd.DataFrame(D_Entropy)\n",
    "    df3 = pd.DataFrame(A_Entropy)\n",
    "    df4 = pd.DataFrame(D_mean)\n",
    "    df5 = pd.DataFrame(A_mean)\n",
    "    df6 = pd.DataFrame(D_std)\n",
    "    df7 = pd.DataFrame(A_std)\n",
    "    \n",
    "    ddd = pd.concat([df,df1,df2,df3,df4,df5,df6,df7], axis = 1)\n",
    "    \n",
    "    dddd = np.array(ddd)\n",
    "    #head = np.array(['stage','cD_energy_fz','cD_energy_cz','cD_energy_c3','cD_energy_c4','cD_energy_pz','cA_energy_fz','cA_energy_cz','cA_energy_c3','cA_energy_c4','cA_energy_pz','D_entropy_fz','D_entropy_cz','D_entropy_c3','D_entropy_c4','D_entropy_pz','A_entropy_fz','A_entropy_cz','A_entropy_c3','A_entropy_c4','A_entropy_pz','D_mean_fz','D_mean_cz','D_mean_c3','D_mean_c4','D_mean_pz','A_mean_fz','A_mean_cz','A_mean_c3','A_mean_c4','A_mean_pz','D_std_fz','D_std_cz','D_std_c3','D_std_c4','D_std_pz','A_std_fz','A_std_cz','A_std_c3','A_std_c4','A_std_pz'])\n",
    "    rr = pd.DataFrame(dddd)\n",
    "    \n",
    "    idx = 0\n",
    "    #new_col = ['2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2','2']\n",
    "    #rr.insert(loc=idx, column='stage', value=new_col)\n",
    "    rr.insert(loc=idx, column='stage', value=state)\n",
    "    \n",
    "    return rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/emanuel/workspace/DWT_FPGA/notebooks/2-1.edf...\n",
      "EDF file detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 307199  =      0.000 ...   599.998 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.1 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.10\n",
      "- Lower transition bandwidth: 0.10 Hz (-6 dB cutoff frequency: 0.05 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 16897 samples (33.002 s)\n",
      "\n",
      "Not setting metadata\n",
      "60 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 60 events and 5121 original time points ...\n",
      "1 bad epochs dropped\n",
      "Extracting EDF parameters from /home/emanuel/workspace/DWT_FPGA/notebooks/2-2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 307199  =      0.000 ...   599.998 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.1 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.10\n",
      "- Lower transition bandwidth: 0.10 Hz (-6 dB cutoff frequency: 0.05 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 16897 samples (33.002 s)\n",
      "\n",
      "Not setting metadata\n",
      "60 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 60 events and 5121 original time points ...\n",
      "1 bad epochs dropped\n",
      "Extracting EDF parameters from /home/emanuel/workspace/DWT_FPGA/notebooks/2-3.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 307199  =      0.000 ...   599.998 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.1 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.10\n",
      "- Lower transition bandwidth: 0.10 Hz (-6 dB cutoff frequency: 0.05 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 16897 samples (33.002 s)\n",
      "\n",
      "Not setting metadata\n",
      "60 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 60 events and 5121 original time points ...\n",
      "1 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "raw_data = prepare_raw_data(\"2-1.edf\")\n",
    "#print(raw_data.shape)\n",
    "cD_Energy, cA_Energy, D_Entropy, A_Entropy, D_mean, A_mean, D_std, A_std = compute_features_cpu(raw_data)\n",
    "dataframe_1 = prepare_dataframe(cD_Energy, cA_Energy, D_Entropy, A_Entropy, D_mean, A_mean, D_std, A_std, 1)\n",
    "\n",
    "raw_data = prepare_raw_data(\"2-2.edf\")\n",
    "#print(raw_data.shape)\n",
    "cD_Energy, cA_Energy, D_Entropy, A_Entropy, D_mean, A_mean, D_std, A_std = compute_features_cpu(raw_data)\n",
    "dataframe_2 = prepare_dataframe(cD_Energy, cA_Energy, D_Entropy, A_Entropy, D_mean, A_mean, D_std, A_std, 2)\n",
    "\n",
    "raw_data = prepare_raw_data(\"2-3.edf\")\n",
    "#print(raw_data.shape)\n",
    "cD_Energy, cA_Energy, D_Entropy, A_Entropy, D_mean, A_mean, D_std, A_std = compute_features_cpu(raw_data)\n",
    "dataframe_3 = prepare_dataframe(cD_Energy, cA_Energy, D_Entropy, A_Entropy, D_mean, A_mean, D_std, A_std, 2)\n",
    "\n",
    "df = pd.concat([dataframe_1, dataframe_2, dataframe_3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stage\n",
       "2    118\n",
       "1     59\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stage\n",
       "2    0.666667\n",
       "1    0.333333\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stage'].value_counts()/float(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score,classification_report, confusion_matrix,cohen_kappa_score,fbeta_score,roc_curve,auc,average_precision_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.utils import resample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = df[df.stage==2]\n",
    "df_minority = df[df.stage==1]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority,\n",
    "                                replace=True,     # sample with replacement\n",
    "                                n_samples=120,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "#df = pd.concat([df_majority, df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stage\n",
       "2    118\n",
       "1     59\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stage\n",
       "2    0.666667\n",
       "1    0.333333\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stage'].value_counts()/float(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Peformance Evauation of RBF SVM **************\n",
      "[[15  0]\n",
      " [ 0 39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "           2       1.00      1.00      1.00        39\n",
      "\n",
      "    accuracy                           1.00        54\n",
      "   macro avg       1.00      1.00      1.00        54\n",
      "weighted avg       1.00      1.00      1.00        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['stage'], axis=1)\n",
    "y = df['stage']\n",
    "\n",
    "X_train_norm, X_test_norm, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 10, shuffle= True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_norm = scaler.fit_transform(X_train_norm)\n",
    "\n",
    "X_test_norm = scaler.transform(X_test_norm)\n",
    "\n",
    "rbf_svm = SVC(C=1,kernel='rbf') # rbf_svm is a RBF support vectors\n",
    "\n",
    "rbf_svm.fit(X_train_norm,y_train)\n",
    "\n",
    "y_rbf_svm=rbf_svm.predict(X_test_norm)\n",
    "\n",
    "print ('************* Peformance Evauation of RBF SVM **************')\n",
    "print(confusion_matrix(y_test,y_rbf_svm))\n",
    "print(classification_report(y_test,y_rbf_svm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
